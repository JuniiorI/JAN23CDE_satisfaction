{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import dateparser\n",
    "\n",
    "def extract_reviews(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    data = []\n",
    "\n",
    "    pagination = soup.find(\"div\", class_=\"styles_pagination__6VmQv\")\n",
    "    last_page = pagination.find_all(\"a\")[-2].text\n",
    "    last_page = pd.to_numeric(last_page)\n",
    "\n",
    "    for i in range(1, last_page + 1):\n",
    "        page_url = url + \"?page=\" + str(i)\n",
    "        page_response = requests.get(page_url)\n",
    "        page_soup = BeautifulSoup(page_response.content, 'html.parser')\n",
    "\n",
    "        reviews = page_soup.find_all(\"div\", class_=\"styles_cardWrapper__LcCPA styles_show__HUXRb styles_reviewCard__9HxJJ\")\n",
    "\n",
    "        for review in reviews:\n",
    "            review_data = {}\n",
    "\n",
    "            review_data[\"Company\"] = soup.find(\"h1\", class_=\"typography_default__hIMlQ typography_appearance-default__AAY17 title_title__i9V__\").span.get_text(strip=True)\n",
    "            review_data[\"Customer\"] = review.find(\"span\", class_=\"typography_heading-xxs__QKBS8 typography_appearance-default__AAY17\").text\n",
    "            review_data[\"Number_review\"] = review.find(\"div\", class_=\"styles_consumerExtraDetails__fxS4S\").find(\"span\").text\n",
    "            review_data[\"Language\"] = review.find(\"div\", class_=\"typography_body-m__xgxZ_ typography_appearance-subtle__8_H2l styles_detailsIcon__Fo_ua\").text\n",
    "            review_data[\"Title\"] = review.find(\"h2\", class_=\"typography_heading-s__f7029 typography_appearance-default__AAY17\").text\n",
    "            review_data[\"Date_review\"] = review.find(\"div\", class_=\"styles_reviewHeader__iU9Px\").time.text\n",
    "            reply = review.find(\"div\").find(\"p\", class_=\"typography_body-m__xgxZ_ typography_appearance-default__AAY17 styles_message__shHhX\")\n",
    "            review_data['Reply'] = reply.text if reply else None\n",
    "            review_data['Date_reply'] = review.find(\"div\", class_=\"styles_content__Hl2Mi\").time.text if reply else None\n",
    "            review_data[\"Rating\"] = review.find(\"section\", class_=\"styles_reviewContentwrapper__zH_9M\").div[\"data-service-review-rating\"]\n",
    "            type_element = review.find_next(\"div\", class_=\"typography_body-m__xgxZ_ typography_appearance-subtle__8_H2l styles_detailsIcon__yqwWi\")\n",
    "            review_data[\"Status\"] = type_element.find(\"span\").text if type_element else None\n",
    "            review_data[\"Experience Date\"] = review.find(\"div\", class_=\"styles_reviewContent__0Q2Tg\").text\n",
    "\n",
    "            data.append(review_data)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "\n",
    "def concat_extracted_companies(younited_url, cofidis_url, orange_url, floa_url, bourso_url, anytime_url):\n",
    "    df_younited = extract_reviews(younited_url)\n",
    "    df_cofidis = extract_reviews(cofidis_url)\n",
    "    df_floa = extract_reviews(floa_url)\n",
    "    df_orange = extract_reviews(orange_url)\n",
    "    df_bourso = extract_reviews(bourso_url)\n",
    "    df_anytime = extract_reviews(anytime_url)\n",
    "\n",
    "    df_all = pd.concat([df_younited, df_cofidis, df_orange, df_floa, df_bourso, df_anytime], ignore_index=True)\n",
    "    return df_all\n",
    "\n",
    "\n",
    "def split_projection(df_all):\n",
    "    df_all[[\"Number_review\", \"review\"]] = df_all[\"Number_review\"].str.split(\" \", n=1, expand=True)\n",
    "    df_all[[\"ExperienceDate\", \"Date_experience\"]]= df_all[\"Experience Date\"].str.split(\":\", n = 1, expand = True)\n",
    "    df_all[[\"Experience\", \"Date\"]]= df_all[\"Experience Date\"].str.split(\"Date\", n = 1, expand = True)\n",
    "\n",
    "\n",
    "    new_df = df_all[[\"Company\", \"Customer\", \"Number_review\", \"Language\", \"Title\", \"Date_review\", \"Reply\", \"Date_reply\", \"Rating\", \"Status\", \"Experience\", \"Date_experience\"]]\n",
    "    return new_df\n",
    "\n",
    "\n",
    "def conversion_type(new_df):\n",
    "\n",
    "    new_df[[\"Number_review\", \"Rating\"]] = new_df[[\"Number_review\", \"Rating\"]].astype(\"int64\")\n",
    "    # Convertir les colonnes \"Date_review\", \"Date_reply\" et \"Date_experience\" en dates\n",
    "    new_df[\"Date_review\"] = new_df[\"Date_review\"].apply(lambda x: dateparser.parse(x) if isinstance(x, str) else x)\n",
    "\n",
    "    # Convertir la colonne \"Date_experience\" en date\n",
    "    new_df[\"Date_experience\"] = new_df[\"Date_experience\"].apply(lambda x: dateparser.parse(x) if isinstance(x, str) else x)\n",
    "\n",
    "    '''# Transformons le datetime en date\n",
    "    new_df[\"Date_review\"] = pd.to_datetime(new_df[\"Date_review\"]).dt.strftime(\"%Y-%m-%d\")\n",
    "    new_df[\"Date_experience\"] = pd.to_datetime(new_df[\"Date_experience\"]).dt.strftime(\"%Y-%m-%d\")'''\n",
    "\n",
    "    #Convertir la colonne \"Date_reply\" en dates\n",
    "    new_df[\"Date_reply\"] = new_df[\"Date_reply\"].apply(lambda x: dateparser.parse(x) if isinstance(x, str) else x)\n",
    "\n",
    "    #Remplacer les valeurs manquantes de \"Date_reply\" par les valeurs de \"Date_review\"\n",
    "    new_df[\"Date_reply\"] = new_df.apply(lambda row: row[\"Date_review\"] if pd.isna(row[\"Date_reply\"]) else row[\"Date_reply\"], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "    return new_df\n",
    "\n",
    "\n",
    "def cleaning_df(new_df):\n",
    "    new_df[\"Status\"] = new_df[\"Status\"].fillna(method=\"bfill\")\n",
    "    new_df[\"Reply\"] = new_df[\"Reply\"].fillna(\"No Reply\")\n",
    "    new_df[\"Date_reply\"] = new_df[\"Date_reply\"].fillna(new_df[\"Date_review\"])\n",
    "    new_df[\"Date_reply\"] = new_df.apply(lambda row: row[\"Date_review\"] if pd.isna(row[\"Date_reply\"]) else row[\"Date_reply\"], axis=1)\n",
    "    new_df = new_df.dropna(how=\"any\")\n",
    "    return new_df\n",
    "\n",
    "\n",
    "def main_dataframe(new_df):\n",
    "    new_df.to_json(\"reviews.json\", orient = 'records')\n",
    "\n",
    "\n",
    "# Exécution du code\n",
    "younited_url = \"https://www.trustpilot.com/review/www.younited-credit.com\"\n",
    "cofidis_url = \"https://www.trustpilot.com/review/www.cofidis.fr\"\n",
    "floa_url = \"https://www.trustpilot.com/review/www.floabank.fr\"\n",
    "orange_url = \"https://www.trustpilot.com/review/www.orangebank.fr\"\n",
    "bourso_url = \"https://www.trustpilot.com/review/boursorama-banque.com\"\n",
    "anytime_url = \"https://www.trustpilot.com/review/anyti.me\"\n",
    "\n",
    "df_all = concat_extracted_companies(younited_url, cofidis_url, orange_url, floa_url, bourso_url, anytime_url)\n",
    "df_splited = split_projection(df_all.copy())\n",
    "df_converted = conversion_type(df_splited.copy())\n",
    "df_cleaned = cleaning_df(df_converted.copy())\n",
    "main_dataframe(df_cleaned)\n",
    "\n",
    "# Affichage du dataframe final en entier\n",
    "#pd.set_option('display.max_columns', None)\n",
    "#pd.set_option('display.max_rows', None)\n",
    "df_cleaned.head()\n",
    "\n",
    "def main_dataframe(new_df):\n",
    "    data_json = new_df.to_json(\"../data/reviews.json\", orient = 'records')\n",
    "    data_csv = new_df.to_csv(\"../data/avis_clients.csv\")\n",
    "\n",
    "# Exécution du code\n",
    "younited_url = \"https://www.trustpilot.com/review/www.younited-credit.com\"\n",
    "cofidis_url = \"https://www.trustpilot.com/review/www.cofidis.fr\"\n",
    "floa_url = \"https://www.trustpilot.com/review/www.floabank.fr\"\n",
    "orange_url = \"https://www.trustpilot.com/review/www.orangebank.fr\"\n",
    "bourso_url = \"https://www.trustpilot.com/review/boursorama-banque.com\"\n",
    "anytime_url = \"https://www.trustpilot.com/review/anyti.me\"\n",
    "\n",
    "df_all = concat_extracted_companies(younited_url, cofidis_url, orange_url, floa_url, bourso_url, anytime_url)\n",
    "df_splited = split_projection(df_all.copy())\n",
    "df_converted = conversion_type(df_splited.copy())\n",
    "df_cleaned = cleaning_df(df_converted.copy())\n",
    "main_dataframe(df_cleaned)\n",
    "\n",
    "# Affichage du dataframe final en entier\n",
    "#pd.set_option('display.max_columns', None)\n",
    "#pd.set_option('display.max_rows', None)\n",
    "df_cleaned.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
